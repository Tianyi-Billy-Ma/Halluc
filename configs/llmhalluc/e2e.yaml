# Experiment
run_name: gsm8k

# Model
# model_name_or_path: /scratch365/tma2/.cache/halluc/models/llama-3.2-1b_gsm8k_sft
# model_name_or_path: meta-llama/Llama-3.2-1B
model_name_or_path: meta-llama/Llama-3.1-8B
template: llama3
stage: sft
finetuning_type: lora

# Dataset
dataset: gsm8k_symbolic_sft_train
eval_dataset: gsm8k_symbolic_sft_eval
# dataset: gsm8k_symbolic_ppo
# eval_dataset: gsm8k_symbolic_sft_eval

# Evaluation
model: hf
tasks: gsm8k_bt
eval_mode: cli

# WandB
wandb_project: llamafactory

# Constants
seed: 3
ddp: 1
hf_username: mtybilly


init_special_tokens: desc_init


# PPO
reward_model: "backtrack"
reward_model_type: "custom"