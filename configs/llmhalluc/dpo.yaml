# Experiment
run_name: gsm8k_bt


# Model
# model_name_or_path: /scratch365/tma2/.cache/halluc/models/llama-3.2-1b_gsm8k_sft
# model_name_or_path: meta-llama/Llama-3.2-1B
# model_name_or_path: meta-llama/Llama-3.2-1B
model_name_or_path: meta-llama/Llama-3.1-8B

template: llama3
# template: llama3_bt
stage: dpo
finetuning_type: lora
fp16: false
bf16: true

# Logging
report_to: wandb

# Dataset
# dataset: gsm8k_train
# eval_dataset: gsm8k_eval
dataset: gsm8k_bt_dpo_train
eval_dataset: gsm8k_bt_dpo_eval
converter: "dpo"

# Evaluation
model: hf
# tasks: gsm8k_comprehensive
tasks: gsm8k_simple

# WandB
wandb_project: huggingface 

# Constants
seed: 3
ddp: 1


deepspeed: configs/deepspeed/ds_z0_config.json

init_special_tokens: desc_init

# SFT
compute_only_loss: false

# PPO
reward_model: "backtrack"
reward_model_type: "custom"