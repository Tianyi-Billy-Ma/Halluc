# Experiment
exp_name: gsm8k
method_name: sft_bt

# Model
model_name_or_path: /scratch365/tma2/.cache/halluc/models/llama-3.2-1b_gsm8k_sft
# model_name_or_path: meta-llama/Llama-3.2-1B
enable_thinking: false
lf_template: llama3
stage: sft
finetuning_type: lora

# Dataset
train_dataset: gsm8k_symbolic_bt_train
eval_dataset: null

# Evaluation
eval_task_name: gsm8k_bt
eval_model: hf

# WandB
wandb_project: llamafactory

# Constants
seed: 3
ddp: 1
hf_username: mtybilly

# Paths
train_config: ./configs/llamafactory/train.yaml
merge_config: ./configs/llamafactory/merge.yaml
eval_config: ./configs/lm_eval/eval.yaml
model_dir: /scratch365/tma2/.cache/halluc/models
output_dir: /scratch365/tma2/.cache/halluc/outputs


new_special_tokens_config: ./configs/llmhalluc/token.yaml